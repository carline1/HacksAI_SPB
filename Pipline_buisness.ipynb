{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Читаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_PATH = r\"\"\n",
    "\n",
    "df_u = pd.read_csv(FULL_PATH + \"users.csv\", sep=';',error_bad_lines=False, quoting=csv.QUOTE_NONE, encoding='utf-8', decimal=',', quotechar='\"')\n",
    "df_t = pd.read_csv(FULL_PATH + \"transactions.csv\", sep=';',error_bad_lines=False, quoting=csv.QUOTE_NONE, encoding='utf-8', decimal=',', quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t['SUM_TRANS'] = df_t['SUM_TRANS'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19995 entries, 0 to 19994\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ID               19995 non-null  int64  \n",
      " 1   MM_IN_BANK       19995 non-null  int64  \n",
      " 2   MM_W_CARD        19995 non-null  int64  \n",
      " 3   AGE              19995 non-null  int64  \n",
      " 4   GENDER           19995 non-null  int64  \n",
      " 5   EDUCATION_LEVEL  19995 non-null  int64  \n",
      " 6   MARITAL_STATUS   19995 non-null  int64  \n",
      " 7   DEPENDANT_CNT    19995 non-null  int64  \n",
      " 8   INCOME_MAIN_AMT  10516 non-null  object \n",
      " 9   REG_CODE         19995 non-null  int64  \n",
      " 10  COUNT_TRANS      18713 non-null  float64\n",
      "dtypes: float64(1), int64(9), object(1)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_u.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_locale_index(pd1):\n",
    "    pd1 = pd1.dropna()\n",
    "    \n",
    "    all_tovar = []\n",
    "    for row in pd1.values:\n",
    "        all_tovar.append(row[5].split(\"\\\\\")[0].strip())\n",
    "    all_tovar = list(set(all_tovar))\n",
    "    dickMarka = {all_tovar[i]: i for i in range(len(all_tovar))}\n",
    "    \n",
    "    location_name_index_list = []\n",
    "    location_names_list = []\n",
    "    pd_values = pd1.values\n",
    "    for row_index in range(len(pd_values)):\n",
    "        value = pd_values[row_index][5].split(\"\\\\\")[0].strip()\n",
    "        index = dickMarka[value]\n",
    "#         print(value, pd1.iloc[row_index]['LOCATION_NAME'])\n",
    "#         pd1.iloc[row_index]['LOCATION_NAME'] = value\n",
    "        location_name_index_list.append(index)\n",
    "        location_names_list.append(value)\n",
    "        \n",
    "    pd1['LOCATION_NAME_INDEX'] = location_name_index_list\n",
    "    pd1['LOCATION_NAME'] = location_names_list\n",
    "#     pd1.to_csv(r'C:\\Users\\Артур\\MarkBestGay/vlad.csv', index=False, sep=\";\")\n",
    "    print(\"Worked!\")\n",
    "    print(pd1)\n",
    "    \n",
    "    return (pd1, dickMarka)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Читем продукты(магазины), которые будем рекомендовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-91c18f7186ea>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pd1['LOCATION_NAME_INDEX'] = location_name_index_list\n",
      "<ipython-input-33-91c18f7186ea>:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pd1['LOCATION_NAME'] = location_names_list\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worked!\n",
      "                         ID  PROD_TYPE           TRANS_DTTM  MCC_CODE  \\\n",
      "0        500000000048605476          1  2021-07-26 00:00:00      5912   \n",
      "1        500000000627114675          2  2021-10-25 13:11:54      5814   \n",
      "19       500000002402742235          2  2021-09-30 19:55:00      5813   \n",
      "25       500000000001441130          1  2021-08-15 07:48:40      5941   \n",
      "29       500000000598956263          2  2021-10-30 02:16:39      5812   \n",
      "...                     ...        ...                  ...       ...   \n",
      "1284494  500000000350335362          2  2021-10-26 13:58:57      5200   \n",
      "1284495  500000000889236204          1  2021-10-21 09:33:29      5411   \n",
      "1284501  500000000049785794          1  2021-10-31 15:27:47      5411   \n",
      "1284502  500000000128977696          1  2021-07-09 10:09:48      5732   \n",
      "1284504  500000000048796429          1  2021-10-29 04:35:10      5999   \n",
      "\n",
      "         SUM_TRANS               LOCATION_NAME  LOCATION_NAME_INDEX  \n",
      "0          2451.00  APTEKA ZDOROV.RU>MOSCOW RU                42981  \n",
      "1           350.00                  YANDEX EDA                49268  \n",
      "19          350.00                  PAB PATRIK                85279  \n",
      "25         3133.00                 5118 SM DVF                76177  \n",
      "29         1300.00                   STOLOVAYA                41749  \n",
      "...            ...                         ...                  ...  \n",
      "1284494     175.30                KHOZYAJKA 88                67443  \n",
      "1284495     112.97                     YM*ozon                93510  \n",
      "1284501     181.00                 TK LENTA-48                87701  \n",
      "1284502     999.00                        U229                77856  \n",
      "1284504    1251.00              MEDOVAYA LAVKA                63814  \n",
      "\n",
      "[226257 rows x 7 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PROD_TYPE</th>\n",
       "      <th>TRANS_DTTM</th>\n",
       "      <th>MCC_CODE</th>\n",
       "      <th>SUM_TRANS</th>\n",
       "      <th>LOCATION_NAME</th>\n",
       "      <th>LOCATION_NAME_INDEX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500000000048605476</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-07-26 00:00:00</td>\n",
       "      <td>5912</td>\n",
       "      <td>2451.0</td>\n",
       "      <td>APTEKA ZDOROV.RU&gt;MOSCOW RU</td>\n",
       "      <td>42981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500000000627114675</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-10-25 13:11:54</td>\n",
       "      <td>5814</td>\n",
       "      <td>350.0</td>\n",
       "      <td>YANDEX EDA</td>\n",
       "      <td>49268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>500000002402742235</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-09-30 19:55:00</td>\n",
       "      <td>5813</td>\n",
       "      <td>350.0</td>\n",
       "      <td>PAB PATRIK</td>\n",
       "      <td>85279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>500000000001441130</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-08-15 07:48:40</td>\n",
       "      <td>5941</td>\n",
       "      <td>3133.0</td>\n",
       "      <td>5118 SM DVF</td>\n",
       "      <td>76177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>500000000598956263</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-10-30 02:16:39</td>\n",
       "      <td>5812</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>STOLOVAYA</td>\n",
       "      <td>41749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID  PROD_TYPE           TRANS_DTTM  MCC_CODE  SUM_TRANS  \\\n",
       "0   500000000048605476          1  2021-07-26 00:00:00      5912     2451.0   \n",
       "1   500000000627114675          2  2021-10-25 13:11:54      5814      350.0   \n",
       "19  500000002402742235          2  2021-09-30 19:55:00      5813      350.0   \n",
       "25  500000000001441130          1  2021-08-15 07:48:40      5941     3133.0   \n",
       "29  500000000598956263          2  2021-10-30 02:16:39      5812     1300.0   \n",
       "\n",
       "                 LOCATION_NAME  LOCATION_NAME_INDEX  \n",
       "0   APTEKA ZDOROV.RU>MOSCOW RU                42981  \n",
       "1                   YANDEX EDA                49268  \n",
       "19                  PAB PATRIK                85279  \n",
       "25                 5118 SM DVF                76177  \n",
       "29                   STOLOVAYA                41749  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_t, label_dict) = csv_locale_index(df_t)\n",
    "df_t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проходимся циклом, по каждому пользователю и делаем предсказание:\n",
    "\n",
    "Если у нас есть только 5-10 транзакций, этого мало, поэтому основываясь на кластере пользователя добавляем популярные в этом кластере покупки (они через какое-то время исчезнуть, но надо же в начале что-то рекомендовать)\n",
    "\n",
    "\n",
    "Если у нас есть большое количество транзакций применяем ALS, который добавляет немного покупок по кластерам и случайных покупок. Так же какую то часть предсказаний мы предлагаем пользователю то, чего он ещё не покупал, но другие похожие(по покупкам) пользователи покупали"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19995\n",
      "129540\n"
     ]
    }
   ],
   "source": [
    "uniq_ids_u = df_u['ID'].unique()\n",
    "uniq_ids_t = df_t['ID'].unique()\n",
    "print(len(uniq_ids_u))\n",
    "print(len(uniq_ids_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_not_real_clusters(n):\n",
    "    clusters = []\n",
    "    for i in range(n):\n",
    "        if(i % 2 == 0):\n",
    "            clusters.append(1)\n",
    "        else:\n",
    "            clusters.append(2)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_u['CLUSTER'] = create_not_real_clusters(df_u.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Находим топ самых продаваемых товаров по кластеру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_dict(user):\n",
    "    c_users = df_u[df_u['CLUSTER'] == user['CLUSTER'].iloc[0]]\n",
    "    return df_t[df_t['ID'].isin(c_users['ID'])]['LOCATION_NAME'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Находим среднюю сумму по кластеру и товару"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_sum_by_cluster_location(cluster, location):\n",
    "    c_users = df_u[df_u['CLUSTER'] == cluster]\n",
    "    trans = df_t[df_t['ID'].isin(c_users['ID'])]\n",
    "    trans = trans[trans['LOCATION_NAME_INDEX'] == location]\n",
    "    return trans['SUM_TRANS'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если пользователь новый, то добавляем транзакции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_transactions(df_t, user):\n",
    "    top = find_top_dict(user)\n",
    "    cluster = user['CLUSTER'].iloc[0]\n",
    "    for i in range(0, 15):\n",
    "        index = random.randint(0, 9)\n",
    "        l_index = label_dict[top.index[index]]\n",
    "        ser = pd.Series({\n",
    "            'ID' : user['ID'],\n",
    "            'PROD_TYPE': 1,\n",
    "            'MCC_CODE' : -1, #такое значение MCC чтобы потом удалить сгенерированные транзакции,\n",
    "            'TRANS_DTTM' : datetime.datetime.now(),\n",
    "            'SUM_TRANS' : mean_sum_by_cluster_location(cluster, l_index),\n",
    "            'LOCATION_NAME' : top[index],\n",
    "            'LOCATION_NAME_INDEX' : l_index\n",
    "        })\n",
    "        df_t.append(ser, ignore_index=True)\n",
    "    return df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sparce_matrix(pd, locale_encoder, user): # датафрейм, словарик назваие-цифры, пользователь\n",
    "    user = df_u[df_u['ID'] == user]\n",
    "    idx = []\n",
    "    values = []\n",
    "    items = [] \n",
    "    top = []\n",
    "    user_pd = pd[pd['ID'] == user]\n",
    "    for trans_index in range(len(user_pd)):\n",
    "        trans = user_pd.iloc[trans_index]\n",
    "        items.append(trans['LOCATION_NAME'])\n",
    "        \n",
    "    if(user['CHANGE'].iloc[0] == 1):\n",
    "        top = find_top_dict(user)\n",
    "        for i in range(3):\n",
    "            index = random.randint(0, 9)\n",
    "            items.append(label_dict[top.index[index]])\n",
    "    \n",
    "    n_items = len(items)\n",
    "    \n",
    "\n",
    "    for pid in items:\n",
    "        value = 1.0\n",
    "        idx.append(locale_encoder[pid])\n",
    "        if(items in top):\n",
    "            value = value * 1.3\n",
    "        \n",
    "        values.append(value)\n",
    "\n",
    "    return sp.coo_matrix(\n",
    "        (np.array(values).astype(np.float32), ([0] * len(idx), idx)), shape=(1, len(locale_encoder)),\n",
    "    )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▉                                                                                                       | 556/19995 [09:09<5:20:00,  1.01it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-97ec000b6f6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtrans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ID'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mid_u\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'COUNT_TRANS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mdf_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_transactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mdf_u\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_u\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ID'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mid_u\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CHANGE'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-1869715f90ed>\u001b[0m in \u001b[0;36madd_transactions\u001b[1;34m(df_t, user)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;34m'LOCATION_NAME_INDEX'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ml_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         })\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mdf_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf_t\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   7980\u001b[0m             \u001b[0mto_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7981\u001b[0m         return (\n\u001b[1;32m-> 7982\u001b[1;33m             concat(\n\u001b[0m\u001b[0;32m   7983\u001b[0m                 \u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7984\u001b[0m                 \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    296\u001b[0m     )\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    518\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m             new_data = concatenate_block_managers(\n\u001b[0m\u001b[0;32m    521\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbm_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m             )\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             b = make_block(\n\u001b[1;32m---> 83\u001b[1;33m                 \u001b[0m_concatenate_join_units\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                 \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36m_concatenate_join_units\u001b[1;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[0;32m    341\u001b[0m             \u001b[0mconcat_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcat_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m         \u001b[0mconcat_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcat_compat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconcat_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcat_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\concat.py\u001b[0m in \u001b[0;36mconcat_compat\u001b[1;34m(to_concat, axis)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0m_contains_datetime\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"timedelta\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtyps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_concat_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mall_empty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for id_u in tqdm(uniq_ids_u):\n",
    "    user = df_u[df_u['ID'] == id_u]\n",
    "    trans = df_t[df_t['ID'] == id_u]\n",
    "    if(user['COUNT_TRANS'].iloc[0] < 5):\n",
    "        df_t = add_transactions(df_t, user)\n",
    "    else:\n",
    "        df_u.loc[df_u['ID'] == id_u, 'CHANGE'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "unique_users = df_t['ID'].unique()\n",
    "train_users = unique_users[:-100]\n",
    "test_users = unique_users[-100:]\n",
    "\n",
    "for user_index in tqdm(range(len(train_users))):\n",
    "    rows.append(make_sparce_matrix(df_test, label_dict, train_users[user_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sparse = sp.vstack(rows).tocsr()\n",
    "x_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = implicit.als.AlternatingLeastSquares(factors=16, regularization=0.0, iterations=8)\n",
    "# model = implicit.nearest_neighbours.CosineRecommender(K=200)\n",
    "model.fit(x_sparse.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'locale_encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-be1ea87e67a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlocale_encoder_reverse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocale_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mlocale_encoder_reverse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# inv_map = {v: k for k, v in my_map.items()}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'locale_encoder' is not defined"
     ]
    }
   ],
   "source": [
    "locale_encoder_reverse = {}\n",
    "for k, v in tqdm(locale_encoder.items()):\n",
    "    locale_encoder_reverse[v] = k\n",
    "# inv_map = {v: k for k, v in my_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_transactions(user, pd):\n",
    "    user_pd = pd[pd['ID'] == user]\n",
    "    return list(user_pd['LOCATION_NAME_INDEX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_user_transactions(train_users[0], location_MarkDick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision(actual, recommended, k=30):\n",
    "    ap_sum = 0\n",
    "    hits = 0\n",
    "    for i in range(k):\n",
    "        product_id = recommended[i] if i < len(recommended) else None\n",
    "        if product_id is not None and product_id in actual:\n",
    "            hits += 1\n",
    "            ap_sum += hits / (i + 1)\n",
    "    return ap_sum / k\n",
    "\n",
    "def normalized_average_precision(actual, recommended, k=30):\n",
    "    actual = set(actual)\n",
    "    if len(actual) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    ap = average_precision(actual, recommended, k=k)\n",
    "    ap_ideal = average_precision(actual, list(actual)[:k], k=k)\n",
    "    return ap / ap_ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_ap = []\n",
    "\n",
    "for user in test_users:\n",
    "    row_sparse = make_sparce_matrix(location_MarkDick, locale_encoder, user)\n",
    "    raw_recs = model.recommend(0, row_sparse, N=30, filter_already_liked_items=False, recalculate_user=True)\n",
    "    recommended_items = [rec[0] for rec in raw_recs]\n",
    "#     print(raw_recs, recommended_items)\n",
    "    \n",
    "    gt_items = get_user_transactions(user, location_MarkDick)\n",
    "    m_ap.append(normalized_average_precision(gt_items, recommended_items, k=30))\n",
    "    \n",
    "print(np.mean(m_ap))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
